(window.webpackJsonp=window.webpackJsonp||[]).push([[17],{716:function(t,a,s){"use strict";s.r(a);var e=s(81),_=Object(e.a)({},(function(){var t=this,a=t._self._c;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"fusion-efficient-and-secure-inference-resilient-to-malicious-servers"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#fusion-efficient-and-secure-inference-resilient-to-malicious-servers"}},[t._v("#")]),t._v(" Fusion: Efficient and Secure Inference Resilient to Malicious Servers")]),t._v(" "),a("p",[t._v("高效且安全的推理对抗恶意服务器")]),t._v(" "),a("h2",{attrs:{id:"_0x00-整体介绍"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_0x00-整体介绍"}},[t._v("#")]),t._v(" 0x00 整体介绍")]),t._v(" "),a("p",[t._v("​\t\t本文介绍了针对机器学习服务中可能出现的恶意服务器问题，提出了一种名为Fusion的意图推理方案，旨在同时实现计算正确性、模型准确性验证和隐私保护，而无需昂贵的加密技术。该方案利用混合检验方法结合查询样本和公共数据集样本，能够让客户端通过比较该方法的计算结果来轻松识别服务器的错误行为。通过实验和对比分析，证明了Fusion方案在速度和通信的使用方面具有优越性。")]),t._v(" "),a("p",[t._v("​\t\t机器学习即服务（MLaaS）是一系列提供机器学习工具作为云计算服务功能的服务。机器学习即服务（MLaaS）供应商提供的工具包括数据可视化、API、自然语言处理、深度学习、面部识别、预测分析等。供应商的数据中心处理实际的计算。")]),t._v(" "),a("h2",{attrs:{id:"_0x01-背景"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_0x01-背景"}},[t._v("#")]),t._v(" 0x01 背景")]),t._v(" "),a("p",[t._v("​\t\t近几年，由于机器学习的快速发展和在各种场景的普遍应用，机器学习即服务（MLaaS）也开始流行起来并为许多普通用户提供使用机器学习服务的便利。虽然MLaaS带来了巨大的便利，但它也存在隐私泄漏风险：")]),t._v(" "),a("ul",[a("li",[t._v("一方面，用户可能将高度敏感数据（例如原始医疗数据）提交到机器学习服务器上，导致隐私泄露；")]),t._v(" "),a("li",[t._v("另一方面，服务器用于机器学习服务的模型本身也存在泄漏训练数据集隐私的风险。")])]),t._v(" "),a("p",[t._v("​\t\t为了解决上述问题，国内外已经有许多专家进行了深入研究：例如采用同态加密、混淆电路和秘密分享等各种加密技术来实现隐私保护的模型预测，保护服务器模型以及用户输入隐私。但是，使用这些技术实现预测计算的成本很高。为了实现实用且保护隐私的MLaaS，大多数这些工作考虑较弱的威胁模型（即半可信敌手，也称“诚实但好奇”敌手，即假设服务器和用户都会诚实地遵守协议，但是他们也会“好奇”地尝试去推测额外信息）。")]),t._v(" "),a("p",[t._v("​\t\t过去使用的方法以及存在的问题：")]),t._v(" "),a("ul",[a("li",[t._v("过去的方法主要使用了加密技术来解决数据隐私保护的问题，但往往需要耗费大量的计算资源和时间。为了实现实用的保护隐私的方式采用的方法，则使用较弱的威胁模型，满足的需求较少。")]),t._v(" "),a("li",[t._v("在现实世界中，我们难以保证服务器总是诚实的。服务器可能不如实按照协议执行（例如，服务器返回随机结果来欺骗用户）。此外，即使服务器遵守协议也无法保证其会产生高质量的结果，无法保证服务器使用的为高质量模型，因为很少有协议可以验证预测结果是否是基于高质量模型产生的。")]),t._v(" "),a("li",[t._v("LevioSA 通过遵循IPS编译器的高级方法实现恶意安全的算术计算（IPS编译器旨在在恶意对手存在的情况下构建安全协议），并将其应用于保护隐私的机器学习。CRYPTFLOW将TensorFlow推理代码到MPC协议。以上方法保证了计算的正确性并保护了隐私，但是没有验证模型的准确性。")]),t._v(" "),a("li",[t._v("使用零知识证明强制服务器为客户端提供正确的结果，但是只能保护服务器模型或者输入数据的隐私。")])]),t._v(" "),a("h2",{attrs:{id:"_0x02-研究目的"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_0x02-研究目的"}},[t._v("#")]),t._v(" 0x02 研究目的")]),t._v(" "),a("p",[t._v("​\t\t在现实世界中，难以保证服务器总是诚实的。真实的情况是服务器可能不如实按照协议执行（例如，服务器返回随机结果来欺骗用户）。此外，即使服务器遵守协议也无法保证其会产生高质量的结果，因为很少有协议可以验证预测结果是否是基于高质量模型产生的。在某些场景下，不准确的结果可能会产生严重后果（例如，MLaaS模型产生的诊断结果将会误导患者）")]),t._v(" "),a("h3",{attrs:{id:"威胁模型"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#威胁模型"}},[t._v("#")]),t._v(" 威胁模型")]),t._v(" "),a("ol",[a("li",[t._v("服务器是恶意的（即恶意安全性），其可能会不遵守协议从而导致不正确的结果。")]),t._v(" "),a("li",[t._v("服务器遵守协议，但是使用低质量模型作为训练模型输入。")])]),t._v(" "),a("p",[t._v("注：此处客户端持有可查询的样本，客户端可以获取公共样本。")]),t._v(" "),a("h3",{attrs:{id:"安全目标"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#安全目标"}},[t._v("#")]),t._v(" 安全目标")]),t._v(" "),a("ol",[a("li",[t._v("服务器和用户都需要保护各自的输入或者模型的隐私性。")]),t._v(" "),a("li",[t._v("保证输出的计算正确性。")]),t._v(" "),a("li",[t._v("客户端确保推理结果的正确性（服务器需要使用高质量模型作为输入）")])]),t._v(" "),a("p",[a("img",{attrs:{src:"/Users/l15hee7/my_blog/docs/.vuepress/public/img/image-20230613221700112.png",alt:"image-20230613221700112"}})]),t._v(" "),a("h2",{attrs:{id:"_0x03-研究方案"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_0x03-研究方案"}},[t._v("#")]),t._v(" 0x03 研究方案")]),t._v(" "),a("p",[t._v("存在恶意服务器时需要实现三个目标：模型的准确性、计算的正确性和隐私")]),t._v(" "),a("p",[t._v("​\t\t我们可以直接将恶意安全的两方计算协议（2PC）应用到神经网络预测中来保证隐私性和计算正确性，但是仍需要额外的技术（例如零知识证明）来验证模型的准确率，因此这种解决方式的开销较大。或者，可以对现有的高效半可信安全预测协议进行修改，以实现恶意安全。但是，这些方案通常也会同时使用多种加密技术，例如同态加密和秘密分享等，同样会造成大量的计算开销。因此如何有效地满足上述三个需求（特别是实现对模型准确率的验证可能需要较多工作）非常具有挑战性。")]),t._v(" "),a("p",[t._v("​\t\t通过观察到MLaaS场景中一个重要的特性，本文克服了上述挑战，并在不使用零知识证明等高成本技术的情况下以高效的方法同时实现了上述三个安全需求。具体来说，我们观察到在机器学习场景中，用户可以提前知道某些输入（即查询样本）的计算结果（公开样本的标签）。如果用户能够提前知道一些输入对应的输出，就可以利用这些预备知识同时验证计算正确性和模型准确率，因为如果服务器不遵守计算协议或使用低质量模型作为输入，用户可以通过比较预期的输出（事先已知）与实际输出来发现异常。")]),t._v(" "),a("h3",{attrs:{id:"fusion"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#fusion"}},[t._v("#")]),t._v(" Fusion")]),t._v(" "),a("p",[t._v("​\t\t基于上述重要发现，本文定制了一种混合结合后验（mix-and-check）的方法，可以同时实现对模型准确率和计算正确性的验证。")]),t._v(" "),a("p",[t._v("​\t\t让用户将一组公开样本与要查询的样本混合在一起，并将它们用作执行隐私保护预测的输入。如果服务器试图欺骗用户且不被其察觉，则服务器必须为某个查询样本的所有副本提供不正确但一致的结果。由于服务器并不知道查询样本和公开样本是如何按照我们的设计混合的，因此用户很容易以极高的概率发现服务器试图欺骗的恶意行为，这样服务器就很难作弊成功。如果用户观察到任意不一致的输出结果（例如，这些公开数据的实际结果不等于其预期结果，或者某个查询样本的多个副本对应的预测结果存在不一致的情况），就说明服务器没有诚实地使用高质量模型作为输入或者没有遵守指定预测协议完成计算。通过这种新型的方式，这些公开样本用于同时验证模型准确率和计算正确性。")]),t._v(" "),a("p",[a("img",{attrs:{src:"/Users/l15hee7/my_blog/docs/.vuepress/public/img/image-20230613233402144.png",alt:"image-20230613233402144"}})]),t._v(" "),a("h4",{attrs:{id:"整体流程"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#整体流程"}},[t._v("#")]),t._v(" 整体流程：")]),t._v(" "),a("ol",[a("li",[t._v("混合数据集生成: 客户端在本地准备混合数据集，并将混合数据集作为输入。")]),t._v(" "),a("li",[t._v("隐私保护的模型预测执行过程：服务器和客户端共同执行半诚实的隐私保护推理协议，推理结果仅向客户端显示。")]),t._v(" "),a("li",[t._v("模型准确率和计算正确性验证：通过对每个查询样本的所有副本的推理结果一致性检查来验证准确性和正确性，如果检查通过则接受结果。")])]),t._v(" "),a("h4",{attrs:{id:"详细设计"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#详细设计"}},[t._v("#")]),t._v(" 详细设计")]),t._v(" "),a("p",[a("img",{attrs:{src:"/Users/l15hee7/my_blog/docs/.vuepress/public/img/image-20230613233812859.png",alt:"image-20230613233812859"}})]),t._v(" "),a("ol",[a("li",[t._v("混合数据集生成: 在此阶段，用户在本地准备一个混合数据集。用户拥有R个查询样本，把每个查询样本复制相同的B份，并同时准备T个与查询样本相同类型的公开样本。接下来，用户使用随机选择的置换来随机排列所有公开样本以及所有查询样本的副本。")]),t._v(" "),a("li",[t._v("隐私保护的模型预测执行过程：在这个阶段，用户通过将上一阶段混合数据集作为其输入来使用服务器提供的预测服务。服务器和用户使用已知的半可信隐私保护预测协议（例如，Cheetah、CrypTFlow2 等）共同执行安全预测计算。")]),t._v(" "),a("li",[t._v("模型准确率和计算正确性验证：用户在得到整个混合数据集的预测结果后，会检查模型准确率和计算正确性。特别是，模型准确率大于设定的阈值（例如，0.95）时，则通过模型准确率验证。同样，用户通过检查每个查询样本所有副本对应预测结果的一致性来验证计算正确性。如果某个查询样本的所有B个副本中存在任意不一致的结果，则认为服务器试图通过提供不正确的预测结果来欺骗用户。如果两个检查都通过了，则用户接受预测结果，否则将拒绝。")])]),t._v(" "),a("h2",{attrs:{id:"_0x04-实验"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_0x04-实验"}},[t._v("#")]),t._v(" 0x04 实验")]),t._v(" "),a("h3",{attrs:{id:"性能对比"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#性能对比"}},[t._v("#")]),t._v(" 性能对比")]),t._v(" "),a("p",[t._v("相比于同样实现了恶意环境下安全的预测方案（2019 CCS’ LevioSA: Lightweight Secure Arithmetic Computation），本文方案在通信开销上减少了30.9倍，在运行时间上减少了48.06倍。")]),t._v(" "),a("p",[a("img",{attrs:{src:"/Users/l15hee7/my_blog/docs/.vuepress/public/img/image-20230614004004141.png",alt:"image-20230614004004141"}})]),t._v(" "),a("h3",{attrs:{id:"效率对比"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#效率对比"}},[t._v("#")]),t._v(" 效率对比")]),t._v(" "),a("p",[t._v("在下表1中，使用Cheetah（2022 Usenix）实例化Fusion时的每个查询样本的平均时间与通信开销与半可信安全的方案CrypTFlow2（2020 CCS），DELPHI（2020 Usenix）和ABY（2015 NDSS）的通信和运行时间进行了比较。值得注意的是，Fusion 的平均成本随着 B 的降低而降低，能够实现更大的性能改进。实验结果表明，当R大于32且B小于等于7和T等于100时，Fusion在通信方面比ABY、DELPHI和CrypTFlow2更有效。例如，当使用MNIST数据集并设置R为32，B为7，T为100时，Fusion的通信成本分别比ABY，DELPHI，CrypTFlow2低14.13，10.61和1.04倍。")]),t._v(" "),a("p",[a("img",{attrs:{src:"/Users/l15hee7/my_blog/docs/.vuepress/public/img/image-20230614004212147.png",alt:"image-20230614004212147"}})]),t._v(" "),a("h2",{attrs:{id:"总结"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#总结"}},[t._v("#")]),t._v(" 总结")]),t._v(" "),a("h3",{attrs:{id:"本文贡献"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#本文贡献"}},[t._v("#")]),t._v(" 本文贡献")]),t._v(" "),a("p",[t._v("​\t\t本文提出了一种名为Fusion的混合检验方法，旨在同时满足计算正确性、模型准确性验证和隐私保护三方面的要求，而无需昂贵的加密技术。Fusion将查询样本和公共数据集样本结合起来进行混合检验，以便让客户端轻松识别服务器的错误行为。将半诚实推理协议转化为了恶意安全推理协议")]),t._v(" "),a("p",[t._v("迁移到")])])}),[],!1,null,null,null);a.default=_.exports}}]);